==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
best_model                               [8, 8]                    --
├─start: 1-1                             [8, 16, 180, 180]         --
│    └─Conv2d: 2-1                       [8, 16, 180, 180]         448
│    └─BatchNorm2d: 2-2                  [8, 16, 180, 180]         32
│    └─LeakyReLU: 2-3                    [8, 16, 180, 180]         --
├─separable_block: 1-2                   [8, 32, 180, 180]         --
│    └─Conv2d: 2-4                       [8, 16, 180, 180]         160
│    └─BatchNorm2d: 2-5                  [8, 16, 180, 180]         32
│    └─LeakyReLU: 2-6                    [8, 16, 180, 180]         --
│    └─Conv2d: 2-7                       [8, 32, 180, 180]         544
│    └─BatchNorm2d: 2-8                  [8, 32, 180, 180]         64
│    └─LeakyReLU: 2-9                    [8, 32, 180, 180]         --
├─separable_block: 1-3                   [8, 64, 90, 90]           --
│    └─Conv2d: 2-10                      [8, 32, 90, 90]           320
│    └─BatchNorm2d: 2-11                 [8, 32, 90, 90]           64
│    └─LeakyReLU: 2-12                   [8, 32, 90, 90]           --
│    └─Conv2d: 2-13                      [8, 64, 90, 90]           2,112
│    └─BatchNorm2d: 2-14                 [8, 64, 90, 90]           128
│    └─LeakyReLU: 2-15                   [8, 64, 90, 90]           --
├─separable_block: 1-4                   [8, 32, 90, 90]           --
│    └─Conv2d: 2-16                      [8, 64, 90, 90]           640
│    └─BatchNorm2d: 2-17                 [8, 64, 90, 90]           128
│    └─LeakyReLU: 2-18                   [8, 64, 90, 90]           --
│    └─Conv2d: 2-19                      [8, 32, 90, 90]           2,080
│    └─BatchNorm2d: 2-20                 [8, 32, 90, 90]           64
│    └─LeakyReLU: 2-21                   [8, 32, 90, 90]           --
├─separable_block: 1-5                   [8, 64, 45, 45]           --
│    └─Conv2d: 2-22                      [8, 32, 45, 45]           320
│    └─BatchNorm2d: 2-23                 [8, 32, 45, 45]           64
│    └─LeakyReLU: 2-24                   [8, 32, 45, 45]           --
│    └─Conv2d: 2-25                      [8, 64, 45, 45]           2,112
│    └─BatchNorm2d: 2-26                 [8, 64, 45, 45]           128
│    └─LeakyReLU: 2-27                   [8, 64, 45, 45]           --
├─separable_block: 1-6                   [8, 128, 45, 45]          --
│    └─Conv2d: 2-28                      [8, 64, 45, 45]           640
│    └─BatchNorm2d: 2-29                 [8, 64, 45, 45]           128
│    └─LeakyReLU: 2-30                   [8, 64, 45, 45]           --
│    └─Conv2d: 2-31                      [8, 128, 45, 45]          8,320
│    └─BatchNorm2d: 2-32                 [8, 128, 45, 45]          256
│    └─LeakyReLU: 2-33                   [8, 128, 45, 45]          --
├─separable_block: 1-7                   [8, 32, 23, 23]           --
│    └─Conv2d: 2-34                      [8, 128, 23, 23]          1,280
│    └─BatchNorm2d: 2-35                 [8, 128, 23, 23]          256
│    └─LeakyReLU: 2-36                   [8, 128, 23, 23]          --
│    └─Conv2d: 2-37                      [8, 32, 23, 23]           4,128
│    └─BatchNorm2d: 2-38                 [8, 32, 23, 23]           64
│    └─LeakyReLU: 2-39                   [8, 32, 23, 23]           --
├─separable_block: 1-8                   [8, 128, 23, 23]          --
│    └─Conv2d: 2-40                      [8, 32, 23, 23]           320
│    └─BatchNorm2d: 2-41                 [8, 32, 23, 23]           64
│    └─LeakyReLU: 2-42                   [8, 32, 23, 23]           --
│    └─Conv2d: 2-43                      [8, 128, 23, 23]          4,224
│    └─BatchNorm2d: 2-44                 [8, 128, 23, 23]          256
│    └─LeakyReLU: 2-45                   [8, 128, 23, 23]          --
├─Linear: 1-9                            [8, 8]                    1,032
├─Softmax: 1-10                          [8, 8]                    --
==========================================================================================
Total params: 30,408
Trainable params: 30,408
Non-trainable params: 0
Total mult-adds (M): 859.14
==========================================================================================
Input size (MB): 12.44
Forward/backward pass size (MB): 560.80
Params size (MB): 0.12
Estimated Total Size (MB): 573.37
==========================================================================================
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
best_model                               [8, 8]                    --
├─start: 1-1                             [8, 16, 180, 180]         --
│    └─Conv2d: 2-1                       [8, 16, 180, 180]         448
│    └─BatchNorm2d: 2-2                  [8, 16, 180, 180]         32
│    └─LeakyReLU: 2-3                    [8, 16, 180, 180]         --
├─separable_block: 1-2                   [8, 32, 180, 180]         --
│    └─Conv2d: 2-4                       [8, 16, 180, 180]         160
│    └─BatchNorm2d: 2-5                  [8, 16, 180, 180]         32
│    └─LeakyReLU: 2-6                    [8, 16, 180, 180]         --
│    └─Conv2d: 2-7                       [8, 32, 180, 180]         544
│    └─BatchNorm2d: 2-8                  [8, 32, 180, 180]         64
│    └─LeakyReLU: 2-9                    [8, 32, 180, 180]         --
├─separable_block: 1-3                   [8, 64, 90, 90]           --
│    └─Conv2d: 2-10                      [8, 32, 90, 90]           320
│    └─BatchNorm2d: 2-11                 [8, 32, 90, 90]           64
│    └─LeakyReLU: 2-12                   [8, 32, 90, 90]           --
│    └─Conv2d: 2-13                      [8, 64, 90, 90]           2,112
│    └─BatchNorm2d: 2-14                 [8, 64, 90, 90]           128
│    └─LeakyReLU: 2-15                   [8, 64, 90, 90]           --
├─separable_block: 1-4                   [8, 32, 90, 90]           --
│    └─Conv2d: 2-16                      [8, 64, 90, 90]           640
│    └─BatchNorm2d: 2-17                 [8, 64, 90, 90]           128
│    └─LeakyReLU: 2-18                   [8, 64, 90, 90]           --
│    └─Conv2d: 2-19                      [8, 32, 90, 90]           2,080
│    └─BatchNorm2d: 2-20                 [8, 32, 90, 90]           64
│    └─LeakyReLU: 2-21                   [8, 32, 90, 90]           --
├─separable_block: 1-5                   [8, 64, 45, 45]           --
│    └─Conv2d: 2-22                      [8, 32, 45, 45]           320
│    └─BatchNorm2d: 2-23                 [8, 32, 45, 45]           64
│    └─LeakyReLU: 2-24                   [8, 32, 45, 45]           --
│    └─Conv2d: 2-25                      [8, 64, 45, 45]           2,112
│    └─BatchNorm2d: 2-26                 [8, 64, 45, 45]           128
│    └─LeakyReLU: 2-27                   [8, 64, 45, 45]           --
├─separable_block: 1-6                   [8, 128, 45, 45]          --
│    └─Conv2d: 2-28                      [8, 64, 45, 45]           640
│    └─BatchNorm2d: 2-29                 [8, 64, 45, 45]           128
│    └─LeakyReLU: 2-30                   [8, 64, 45, 45]           --
│    └─Conv2d: 2-31                      [8, 128, 45, 45]          8,320
│    └─BatchNorm2d: 2-32                 [8, 128, 45, 45]          256
│    └─LeakyReLU: 2-33                   [8, 128, 45, 45]          --
├─separable_block: 1-7                   [8, 32, 23, 23]           --
│    └─Conv2d: 2-34                      [8, 128, 23, 23]          1,280
│    └─BatchNorm2d: 2-35                 [8, 128, 23, 23]          256
│    └─LeakyReLU: 2-36                   [8, 128, 23, 23]          --
│    └─Conv2d: 2-37                      [8, 32, 23, 23]           4,128
│    └─BatchNorm2d: 2-38                 [8, 32, 23, 23]           64
│    └─LeakyReLU: 2-39                   [8, 32, 23, 23]           --
├─separable_block: 1-8                   [8, 128, 23, 23]          --
│    └─Conv2d: 2-40                      [8, 32, 23, 23]           320
│    └─BatchNorm2d: 2-41                 [8, 32, 23, 23]           64
│    └─LeakyReLU: 2-42                   [8, 32, 23, 23]           --
│    └─Conv2d: 2-43                      [8, 128, 23, 23]          4,224
│    └─BatchNorm2d: 2-44                 [8, 128, 23, 23]          256
│    └─LeakyReLU: 2-45                   [8, 128, 23, 23]          --
├─Linear: 1-9                            [8, 8]                    1,032
├─Softmax: 1-10                          [8, 8]                    --
==========================================================================================
Total params: 30,408
Trainable params: 30,408
Non-trainable params: 0
Total mult-adds (M): 859.14
==========================================================================================
Input size (MB): 12.44
Forward/backward pass size (MB): 560.80
Params size (MB): 0.12
Estimated Total Size (MB): 573.37
==========================================================================================
Epoch: 0 | Loss: 2.07912, Train Accuracy: 0.10000, Test Loss: 2.07698, Test Accuracy: 0.16128
Epoch: 10 | Loss: 1.97782, Train Accuracy: 0.28250, Test Loss: 1.97459, Test Accuracy: 0.29021
Epoch: 20 | Loss: 1.92776, Train Accuracy: 0.34750, Test Loss: 1.93490, Test Accuracy: 0.36495
Epoch: 30 | Loss: 1.94529, Train Accuracy: 0.34500, Test Loss: 1.93488, Test Accuracy: 0.37281
Epoch: 40 | Loss: 1.94570, Train Accuracy: 0.33750, Test Loss: 1.91709, Test Accuracy: 0.37893
Epoch: 50 | Loss: 1.94673, Train Accuracy: 0.34500, Test Loss: 1.89981, Test Accuracy: 0.36451
Epoch: 60 | Loss: 1.93747, Train Accuracy: 0.35250, Test Loss: 1.94555, Test Accuracy: 0.30638
Epoch: 70 | Loss: 1.93926, Train Accuracy: 0.34500, Test Loss: 1.88275, Test Accuracy: 0.37631
Epoch: 80 | Loss: 1.93760, Train Accuracy: 0.34250, Test Loss: 1.91308, Test Accuracy: 0.36014
Epoch: 90 | Loss: 1.93541, Train Accuracy: 0.35000, Test Loss: 1.93627, Test Accuracy: 0.34178
Epoch: 100 | Loss: 1.94291, Train Accuracy: 0.34500, Test Loss: 1.91352, Test Accuracy: 0.36626
Epoch: 110 | Loss: 1.93355, Train Accuracy: 0.35500, Test Loss: 1.90352, Test Accuracy: 0.37806
Epoch: 120 | Loss: 1.93804, Train Accuracy: 0.35000, Test Loss: 1.89845, Test Accuracy: 0.38112
Epoch: 130 | Loss: 1.93055, Train Accuracy: 0.35000, Test Loss: 1.92473, Test Accuracy: 0.34965
Epoch: 140 | Loss: 1.93687, Train Accuracy: 0.35250, Test Loss: 1.90444, Test Accuracy: 0.37194
Epoch: 150 | Loss: 1.93678, Train Accuracy: 0.35000, Test Loss: 1.91109, Test Accuracy: 0.38112
Epoch: 160 | Loss: 1.92920, Train Accuracy: 0.35750, Test Loss: 1.93985, Test Accuracy: 0.36058
Epoch: 170 | Loss: 1.94141, Train Accuracy: 0.34250, Test Loss: 1.89548, Test Accuracy: 0.37806
Epoch: 180 | Loss: 1.93736, Train Accuracy: 0.35500, Test Loss: 1.87309, Test Accuracy: 0.37893
Epoch: 190 | Loss: 1.93958, Train Accuracy: 0.35500, Test Loss: 1.91532, Test Accuracy: 0.37194