==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
best_model                               [8, 8]                    --
├─start: 1-1                             [8, 16, 180, 180]         --
│    └─Conv2d: 2-1                       [8, 16, 180, 180]         448
│    └─BatchNorm2d: 2-2                  [8, 16, 180, 180]         32
│    └─LeakyReLU: 2-3                    [8, 16, 180, 180]         --
├─separable_block: 1-2                   [8, 32, 180, 180]         --
│    └─Conv2d: 2-4                       [8, 16, 180, 180]         160
│    └─BatchNorm2d: 2-5                  [8, 16, 180, 180]         32
│    └─LeakyReLU: 2-6                    [8, 16, 180, 180]         --
│    └─Conv2d: 2-7                       [8, 32, 180, 180]         544
│    └─BatchNorm2d: 2-8                  [8, 32, 180, 180]         64
│    └─LeakyReLU: 2-9                    [8, 32, 180, 180]         --
├─separable_block: 1-3                   [8, 64, 90, 90]           --
│    └─Conv2d: 2-10                      [8, 32, 90, 90]           320
│    └─BatchNorm2d: 2-11                 [8, 32, 90, 90]           64
│    └─LeakyReLU: 2-12                   [8, 32, 90, 90]           --
│    └─Conv2d: 2-13                      [8, 64, 90, 90]           2,112
│    └─BatchNorm2d: 2-14                 [8, 64, 90, 90]           128
│    └─LeakyReLU: 2-15                   [8, 64, 90, 90]           --
├─separable_block: 1-4                   [8, 32, 90, 90]           --
│    └─Conv2d: 2-16                      [8, 64, 90, 90]           640
│    └─BatchNorm2d: 2-17                 [8, 64, 90, 90]           128
│    └─LeakyReLU: 2-18                   [8, 64, 90, 90]           --
│    └─Conv2d: 2-19                      [8, 32, 90, 90]           2,080
│    └─BatchNorm2d: 2-20                 [8, 32, 90, 90]           64
│    └─LeakyReLU: 2-21                   [8, 32, 90, 90]           --
├─separable_block: 1-5                   [8, 64, 45, 45]           --
│    └─Conv2d: 2-22                      [8, 32, 45, 45]           320
│    └─BatchNorm2d: 2-23                 [8, 32, 45, 45]           64
│    └─LeakyReLU: 2-24                   [8, 32, 45, 45]           --
│    └─Conv2d: 2-25                      [8, 64, 45, 45]           2,112
│    └─BatchNorm2d: 2-26                 [8, 64, 45, 45]           128
│    └─LeakyReLU: 2-27                   [8, 64, 45, 45]           --
├─separable_block: 1-6                   [8, 128, 45, 45]          --
│    └─Conv2d: 2-28                      [8, 64, 45, 45]           640
│    └─BatchNorm2d: 2-29                 [8, 64, 45, 45]           128
│    └─LeakyReLU: 2-30                   [8, 64, 45, 45]           --
│    └─Conv2d: 2-31                      [8, 128, 45, 45]          8,320
│    └─BatchNorm2d: 2-32                 [8, 128, 45, 45]          256
│    └─LeakyReLU: 2-33                   [8, 128, 45, 45]          --
├─separable_block: 1-7                   [8, 32, 23, 23]           --
│    └─Conv2d: 2-34                      [8, 128, 23, 23]          1,280
│    └─BatchNorm2d: 2-35                 [8, 128, 23, 23]          256
│    └─LeakyReLU: 2-36                   [8, 128, 23, 23]          --
│    └─Conv2d: 2-37                      [8, 32, 23, 23]           4,128
│    └─BatchNorm2d: 2-38                 [8, 32, 23, 23]           64
│    └─LeakyReLU: 2-39                   [8, 32, 23, 23]           --
├─separable_block: 1-8                   [8, 128, 23, 23]          --
│    └─Conv2d: 2-40                      [8, 32, 23, 23]           320
│    └─BatchNorm2d: 2-41                 [8, 32, 23, 23]           64
│    └─LeakyReLU: 2-42                   [8, 32, 23, 23]           --
│    └─Conv2d: 2-43                      [8, 128, 23, 23]          4,224
│    └─BatchNorm2d: 2-44                 [8, 128, 23, 23]          256
│    └─LeakyReLU: 2-45                   [8, 128, 23, 23]          --
├─Linear: 1-9                            [8, 8]                    1,032
├─Softmax: 1-10                          [8, 8]                    --
==========================================================================================
Total params: 30,408
Trainable params: 30,408
Non-trainable params: 0
Total mult-adds (M): 859.14
==========================================================================================
Input size (MB): 12.44
Forward/backward pass size (MB): 560.80
Params size (MB): 0.12
Estimated Total Size (MB): 573.37
==========================================================================================
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
best_model                               [8, 8]                    --
├─start: 1-1                             [8, 16, 180, 180]         --
│    └─Conv2d: 2-1                       [8, 16, 180, 180]         448
│    └─BatchNorm2d: 2-2                  [8, 16, 180, 180]         32
│    └─LeakyReLU: 2-3                    [8, 16, 180, 180]         --
├─separable_block: 1-2                   [8, 32, 180, 180]         --
│    └─Conv2d: 2-4                       [8, 16, 180, 180]         160
│    └─BatchNorm2d: 2-5                  [8, 16, 180, 180]         32
│    └─LeakyReLU: 2-6                    [8, 16, 180, 180]         --
│    └─Conv2d: 2-7                       [8, 32, 180, 180]         544
│    └─BatchNorm2d: 2-8                  [8, 32, 180, 180]         64
│    └─LeakyReLU: 2-9                    [8, 32, 180, 180]         --
├─separable_block: 1-3                   [8, 64, 90, 90]           --
│    └─Conv2d: 2-10                      [8, 32, 90, 90]           320
│    └─BatchNorm2d: 2-11                 [8, 32, 90, 90]           64
│    └─LeakyReLU: 2-12                   [8, 32, 90, 90]           --
│    └─Conv2d: 2-13                      [8, 64, 90, 90]           2,112
│    └─BatchNorm2d: 2-14                 [8, 64, 90, 90]           128
│    └─LeakyReLU: 2-15                   [8, 64, 90, 90]           --
├─separable_block: 1-4                   [8, 32, 90, 90]           --
│    └─Conv2d: 2-16                      [8, 64, 90, 90]           640
│    └─BatchNorm2d: 2-17                 [8, 64, 90, 90]           128
│    └─LeakyReLU: 2-18                   [8, 64, 90, 90]           --
│    └─Conv2d: 2-19                      [8, 32, 90, 90]           2,080
│    └─BatchNorm2d: 2-20                 [8, 32, 90, 90]           64
│    └─LeakyReLU: 2-21                   [8, 32, 90, 90]           --
├─separable_block: 1-5                   [8, 64, 45, 45]           --
│    └─Conv2d: 2-22                      [8, 32, 45, 45]           320
│    └─BatchNorm2d: 2-23                 [8, 32, 45, 45]           64
│    └─LeakyReLU: 2-24                   [8, 32, 45, 45]           --
│    └─Conv2d: 2-25                      [8, 64, 45, 45]           2,112
│    └─BatchNorm2d: 2-26                 [8, 64, 45, 45]           128
│    └─LeakyReLU: 2-27                   [8, 64, 45, 45]           --
├─separable_block: 1-6                   [8, 128, 45, 45]          --
│    └─Conv2d: 2-28                      [8, 64, 45, 45]           640
│    └─BatchNorm2d: 2-29                 [8, 64, 45, 45]           128
│    └─LeakyReLU: 2-30                   [8, 64, 45, 45]           --
│    └─Conv2d: 2-31                      [8, 128, 45, 45]          8,320
│    └─BatchNorm2d: 2-32                 [8, 128, 45, 45]          256
│    └─LeakyReLU: 2-33                   [8, 128, 45, 45]          --
├─separable_block: 1-7                   [8, 32, 23, 23]           --
│    └─Conv2d: 2-34                      [8, 128, 23, 23]          1,280
│    └─BatchNorm2d: 2-35                 [8, 128, 23, 23]          256
│    └─LeakyReLU: 2-36                   [8, 128, 23, 23]          --
│    └─Conv2d: 2-37                      [8, 32, 23, 23]           4,128
│    └─BatchNorm2d: 2-38                 [8, 32, 23, 23]           64
│    └─LeakyReLU: 2-39                   [8, 32, 23, 23]           --
├─separable_block: 1-8                   [8, 128, 23, 23]          --
│    └─Conv2d: 2-40                      [8, 32, 23, 23]           320
│    └─BatchNorm2d: 2-41                 [8, 32, 23, 23]           64
│    └─LeakyReLU: 2-42                   [8, 32, 23, 23]           --
│    └─Conv2d: 2-43                      [8, 128, 23, 23]          4,224
│    └─BatchNorm2d: 2-44                 [8, 128, 23, 23]          256
│    └─LeakyReLU: 2-45                   [8, 128, 23, 23]          --
├─Linear: 1-9                            [8, 8]                    1,032
├─Softmax: 1-10                          [8, 8]                    --
==========================================================================================
Total params: 30,408
Trainable params: 30,408
Non-trainable params: 0
Total mult-adds (M): 859.14
==========================================================================================
Input size (MB): 12.44
Forward/backward pass size (MB): 560.80
Params size (MB): 0.12
Estimated Total Size (MB): 573.37
==========================================================================================
Epoch: 0 | Loss: 2.06745, Train Accuracy: 0.17000, Test Loss: 2.10327, Test Accuracy: 0.09178
Epoch: 10 | Loss: 1.78180, Train Accuracy: 0.53500, Test Loss: 1.77808, Test Accuracy: 0.52185
Epoch: 20 | Loss: 1.72978, Train Accuracy: 0.60750, Test Loss: 1.70344, Test Accuracy: 0.64991
Epoch: 30 | Loss: 1.65087, Train Accuracy: 0.71500, Test Loss: 1.60428, Test Accuracy: 0.73033
Epoch: 40 | Loss: 1.56240, Train Accuracy: 0.80250, Test Loss: 1.54833, Test Accuracy: 0.78059
Epoch: 50 | Loss: 1.56463, Train Accuracy: 0.80500, Test Loss: 1.54312, Test Accuracy: 0.78846
Epoch: 60 | Loss: 1.51528, Train Accuracy: 0.85500, Test Loss: 1.57785, Test Accuracy: 0.74432
Epoch: 70 | Loss: 1.52336, Train Accuracy: 0.86000, Test Loss: 1.49938, Test Accuracy: 0.82517
Epoch: 80 | Loss: 1.51130, Train Accuracy: 0.87000, Test Loss: 1.52296, Test Accuracy: 0.79196
Epoch: 90 | Loss: 1.49581, Train Accuracy: 0.85000, Test Loss: 1.50455, Test Accuracy: 0.82605
Epoch: 100 | Loss: 1.48222, Train Accuracy: 0.87250, Test Loss: 1.56279, Test Accuracy: 0.75743
Epoch: 110 | Loss: 1.48640, Train Accuracy: 0.89250, Test Loss: 1.54928, Test Accuracy: 0.77753
Epoch: 120 | Loss: 1.49060, Train Accuracy: 0.87000, Test Loss: 1.51430, Test Accuracy: 0.80944
Epoch: 130 | Loss: 1.48362, Train Accuracy: 0.88750, Test Loss: 1.50865, Test Accuracy: 0.80988
Epoch: 140 | Loss: 1.47069, Train Accuracy: 0.88750, Test Loss: 1.50789, Test Accuracy: 0.80769
Epoch: 150 | Loss: 1.48091, Train Accuracy: 0.88250, Test Loss: 1.51348, Test Accuracy: 0.80988
Epoch: 160 | Loss: 1.46547, Train Accuracy: 0.90000, Test Loss: 1.51397, Test Accuracy: 0.79983
Epoch: 170 | Loss: 1.45490, Train Accuracy: 0.90500, Test Loss: 1.49056, Test Accuracy: 0.84091
Epoch: 180 | Loss: 1.47281, Train Accuracy: 0.88500, Test Loss: 1.50084, Test Accuracy: 0.82255
Epoch: 190 | Loss: 1.45803, Train Accuracy: 0.89000, Test Loss: 1.49925, Test Accuracy: 0.81731