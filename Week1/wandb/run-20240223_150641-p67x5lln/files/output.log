==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
best_model                               [8, 8]                    --
├─start: 1-1                             [8, 16, 180, 180]         --
│    └─Conv2d: 2-1                       [8, 16, 180, 180]         448
│    └─BatchNorm2d: 2-2                  [8, 16, 180, 180]         32
│    └─LeakyReLU: 2-3                    [8, 16, 180, 180]         --
├─separable_block: 1-2                   [8, 32, 180, 180]         --
│    └─Conv2d: 2-4                       [8, 16, 180, 180]         160
│    └─BatchNorm2d: 2-5                  [8, 16, 180, 180]         32
│    └─LeakyReLU: 2-6                    [8, 16, 180, 180]         --
│    └─Conv2d: 2-7                       [8, 32, 180, 180]         544
│    └─BatchNorm2d: 2-8                  [8, 32, 180, 180]         64
│    └─LeakyReLU: 2-9                    [8, 32, 180, 180]         --
├─separable_block: 1-3                   [8, 64, 90, 90]           --
│    └─Conv2d: 2-10                      [8, 32, 90, 90]           320
│    └─BatchNorm2d: 2-11                 [8, 32, 90, 90]           64
│    └─LeakyReLU: 2-12                   [8, 32, 90, 90]           --
│    └─Conv2d: 2-13                      [8, 64, 90, 90]           2,112
│    └─BatchNorm2d: 2-14                 [8, 64, 90, 90]           128
│    └─LeakyReLU: 2-15                   [8, 64, 90, 90]           --
├─separable_block: 1-4                   [8, 32, 90, 90]           --
│    └─Conv2d: 2-16                      [8, 64, 90, 90]           640
│    └─BatchNorm2d: 2-17                 [8, 64, 90, 90]           128
│    └─LeakyReLU: 2-18                   [8, 64, 90, 90]           --
│    └─Conv2d: 2-19                      [8, 32, 90, 90]           2,080
│    └─BatchNorm2d: 2-20                 [8, 32, 90, 90]           64
│    └─LeakyReLU: 2-21                   [8, 32, 90, 90]           --
├─separable_block: 1-5                   [8, 64, 45, 45]           --
│    └─Conv2d: 2-22                      [8, 32, 45, 45]           320
│    └─BatchNorm2d: 2-23                 [8, 32, 45, 45]           64
│    └─LeakyReLU: 2-24                   [8, 32, 45, 45]           --
│    └─Conv2d: 2-25                      [8, 64, 45, 45]           2,112
│    └─BatchNorm2d: 2-26                 [8, 64, 45, 45]           128
│    └─LeakyReLU: 2-27                   [8, 64, 45, 45]           --
├─separable_block: 1-6                   [8, 128, 45, 45]          --
│    └─Conv2d: 2-28                      [8, 64, 45, 45]           640
│    └─BatchNorm2d: 2-29                 [8, 64, 45, 45]           128
│    └─LeakyReLU: 2-30                   [8, 64, 45, 45]           --
│    └─Conv2d: 2-31                      [8, 128, 45, 45]          8,320
│    └─BatchNorm2d: 2-32                 [8, 128, 45, 45]          256
│    └─LeakyReLU: 2-33                   [8, 128, 45, 45]          --
├─separable_block: 1-7                   [8, 32, 23, 23]           --
│    └─Conv2d: 2-34                      [8, 128, 23, 23]          1,280
│    └─BatchNorm2d: 2-35                 [8, 128, 23, 23]          256
│    └─LeakyReLU: 2-36                   [8, 128, 23, 23]          --
│    └─Conv2d: 2-37                      [8, 32, 23, 23]           4,128
│    └─BatchNorm2d: 2-38                 [8, 32, 23, 23]           64
│    └─LeakyReLU: 2-39                   [8, 32, 23, 23]           --
├─separable_block: 1-8                   [8, 128, 23, 23]          --
│    └─Conv2d: 2-40                      [8, 32, 23, 23]           320
│    └─BatchNorm2d: 2-41                 [8, 32, 23, 23]           64
│    └─LeakyReLU: 2-42                   [8, 32, 23, 23]           --
│    └─Conv2d: 2-43                      [8, 128, 23, 23]          4,224
│    └─BatchNorm2d: 2-44                 [8, 128, 23, 23]          256
│    └─LeakyReLU: 2-45                   [8, 128, 23, 23]          --
├─Linear: 1-9                            [8, 8]                    1,032
├─Softmax: 1-10                          [8, 8]                    --
==========================================================================================
Total params: 30,408
Trainable params: 30,408
Non-trainable params: 0
Total mult-adds (M): 859.14
==========================================================================================
Input size (MB): 12.44
Forward/backward pass size (MB): 560.80
Params size (MB): 0.12
Estimated Total Size (MB): 573.37
==========================================================================================
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
best_model                               [8, 8]                    --
├─start: 1-1                             [8, 16, 180, 180]         --
│    └─Conv2d: 2-1                       [8, 16, 180, 180]         448
│    └─BatchNorm2d: 2-2                  [8, 16, 180, 180]         32
│    └─LeakyReLU: 2-3                    [8, 16, 180, 180]         --
├─separable_block: 1-2                   [8, 32, 180, 180]         --
│    └─Conv2d: 2-4                       [8, 16, 180, 180]         160
│    └─BatchNorm2d: 2-5                  [8, 16, 180, 180]         32
│    └─LeakyReLU: 2-6                    [8, 16, 180, 180]         --
│    └─Conv2d: 2-7                       [8, 32, 180, 180]         544
│    └─BatchNorm2d: 2-8                  [8, 32, 180, 180]         64
│    └─LeakyReLU: 2-9                    [8, 32, 180, 180]         --
├─separable_block: 1-3                   [8, 64, 90, 90]           --
│    └─Conv2d: 2-10                      [8, 32, 90, 90]           320
│    └─BatchNorm2d: 2-11                 [8, 32, 90, 90]           64
│    └─LeakyReLU: 2-12                   [8, 32, 90, 90]           --
│    └─Conv2d: 2-13                      [8, 64, 90, 90]           2,112
│    └─BatchNorm2d: 2-14                 [8, 64, 90, 90]           128
│    └─LeakyReLU: 2-15                   [8, 64, 90, 90]           --
├─separable_block: 1-4                   [8, 32, 90, 90]           --
│    └─Conv2d: 2-16                      [8, 64, 90, 90]           640
│    └─BatchNorm2d: 2-17                 [8, 64, 90, 90]           128
│    └─LeakyReLU: 2-18                   [8, 64, 90, 90]           --
│    └─Conv2d: 2-19                      [8, 32, 90, 90]           2,080
│    └─BatchNorm2d: 2-20                 [8, 32, 90, 90]           64
│    └─LeakyReLU: 2-21                   [8, 32, 90, 90]           --
├─separable_block: 1-5                   [8, 64, 45, 45]           --
│    └─Conv2d: 2-22                      [8, 32, 45, 45]           320
│    └─BatchNorm2d: 2-23                 [8, 32, 45, 45]           64
│    └─LeakyReLU: 2-24                   [8, 32, 45, 45]           --
│    └─Conv2d: 2-25                      [8, 64, 45, 45]           2,112
│    └─BatchNorm2d: 2-26                 [8, 64, 45, 45]           128
│    └─LeakyReLU: 2-27                   [8, 64, 45, 45]           --
├─separable_block: 1-6                   [8, 128, 45, 45]          --
│    └─Conv2d: 2-28                      [8, 64, 45, 45]           640
│    └─BatchNorm2d: 2-29                 [8, 64, 45, 45]           128
│    └─LeakyReLU: 2-30                   [8, 64, 45, 45]           --
│    └─Conv2d: 2-31                      [8, 128, 45, 45]          8,320
│    └─BatchNorm2d: 2-32                 [8, 128, 45, 45]          256
│    └─LeakyReLU: 2-33                   [8, 128, 45, 45]          --
├─separable_block: 1-7                   [8, 32, 23, 23]           --
│    └─Conv2d: 2-34                      [8, 128, 23, 23]          1,280
│    └─BatchNorm2d: 2-35                 [8, 128, 23, 23]          256
│    └─LeakyReLU: 2-36                   [8, 128, 23, 23]          --
│    └─Conv2d: 2-37                      [8, 32, 23, 23]           4,128
│    └─BatchNorm2d: 2-38                 [8, 32, 23, 23]           64
│    └─LeakyReLU: 2-39                   [8, 32, 23, 23]           --
├─separable_block: 1-8                   [8, 128, 23, 23]          --
│    └─Conv2d: 2-40                      [8, 32, 23, 23]           320
│    └─BatchNorm2d: 2-41                 [8, 32, 23, 23]           64
│    └─LeakyReLU: 2-42                   [8, 32, 23, 23]           --
│    └─Conv2d: 2-43                      [8, 128, 23, 23]          4,224
│    └─BatchNorm2d: 2-44                 [8, 128, 23, 23]          256
│    └─LeakyReLU: 2-45                   [8, 128, 23, 23]          --
├─Linear: 1-9                            [8, 8]                    1,032
├─Softmax: 1-10                          [8, 8]                    --
==========================================================================================
Total params: 30,408
Trainable params: 30,408
Non-trainable params: 0
Total mult-adds (M): 859.14
==========================================================================================
Input size (MB): 12.44
Forward/backward pass size (MB): 560.80
Params size (MB): 0.12
Estimated Total Size (MB): 573.37
==========================================================================================
Epoch: 0 | Loss: 2.07760, Train Accuracy: 0.11500, Test Loss: 2.07240, Test Accuracy: 0.22203
Epoch: 10 | Loss: 1.88653, Train Accuracy: 0.36750, Test Loss: 1.86003, Test Accuracy: 0.44624
Epoch: 20 | Loss: 1.84731, Train Accuracy: 0.43500, Test Loss: 1.85544, Test Accuracy: 0.46066
Epoch: 30 | Loss: 1.80356, Train Accuracy: 0.51250, Test Loss: 1.77134, Test Accuracy: 0.55507
Epoch: 40 | Loss: 1.71272, Train Accuracy: 0.63750, Test Loss: 1.64264, Test Accuracy: 0.68269
Epoch: 50 | Loss: 1.66971, Train Accuracy: 0.68250, Test Loss: 1.66443, Test Accuracy: 0.64030
Epoch: 60 | Loss: 1.62831, Train Accuracy: 0.70750, Test Loss: 1.64129, Test Accuracy: 0.65734
Epoch: 70 | Loss: 1.63441, Train Accuracy: 0.71000, Test Loss: 1.60227, Test Accuracy: 0.71066
Epoch: 80 | Loss: 1.62062, Train Accuracy: 0.73750, Test Loss: 1.61583, Test Accuracy: 0.67745
Epoch: 90 | Loss: 1.57254, Train Accuracy: 0.77750, Test Loss: 1.58397, Test Accuracy: 0.71547
Epoch: 100 | Loss: 1.57860, Train Accuracy: 0.76250, Test Loss: 1.64722, Test Accuracy: 0.63462
Epoch: 110 | Loss: 1.58650, Train Accuracy: 0.75500, Test Loss: 1.60211, Test Accuracy: 0.69100
Epoch: 120 | Loss: 1.58078, Train Accuracy: 0.78250, Test Loss: 1.55276, Test Accuracy: 0.81119
Epoch: 130 | Loss: 1.51506, Train Accuracy: 0.85250, Test Loss: 1.51612, Test Accuracy: 0.82255
Epoch: 140 | Loss: 1.52593, Train Accuracy: 0.84750, Test Loss: 1.55674, Test Accuracy: 0.75962
Epoch: 150 | Loss: 1.50959, Train Accuracy: 0.84750, Test Loss: 1.49718, Test Accuracy: 0.82867
Epoch: 160 | Loss: 1.51535, Train Accuracy: 0.84750, Test Loss: 1.48909, Test Accuracy: 0.83916
Epoch: 170 | Loss: 1.49367, Train Accuracy: 0.87750, Test Loss: 1.54623, Test Accuracy: 0.77928
Epoch: 180 | Loss: 1.47524, Train Accuracy: 0.90000, Test Loss: 1.47813, Test Accuracy: 0.83392
Epoch: 190 | Loss: 1.48606, Train Accuracy: 0.87750, Test Loss: 1.52550, Test Accuracy: 0.80463