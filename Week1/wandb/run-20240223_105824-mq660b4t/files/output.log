==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
best_model                               [8, 8]                    --
├─start: 1-1                             [8, 16, 180, 180]         --
│    └─Conv2d: 2-1                       [8, 16, 180, 180]         448
│    └─BatchNorm2d: 2-2                  [8, 16, 180, 180]         32
│    └─LeakyReLU: 2-3                    [8, 16, 180, 180]         --
├─separable_block: 1-2                   [8, 32, 180, 180]         --
│    └─Conv2d: 2-4                       [8, 16, 180, 180]         160
│    └─BatchNorm2d: 2-5                  [8, 16, 180, 180]         32
│    └─LeakyReLU: 2-6                    [8, 16, 180, 180]         --
│    └─Conv2d: 2-7                       [8, 32, 180, 180]         544
│    └─BatchNorm2d: 2-8                  [8, 32, 180, 180]         64
│    └─LeakyReLU: 2-9                    [8, 32, 180, 180]         --
├─separable_block: 1-3                   [8, 64, 90, 90]           --
│    └─Conv2d: 2-10                      [8, 32, 90, 90]           320
│    └─BatchNorm2d: 2-11                 [8, 32, 90, 90]           64
│    └─LeakyReLU: 2-12                   [8, 32, 90, 90]           --
│    └─Conv2d: 2-13                      [8, 64, 90, 90]           2,112
│    └─BatchNorm2d: 2-14                 [8, 64, 90, 90]           128
│    └─LeakyReLU: 2-15                   [8, 64, 90, 90]           --
├─separable_block: 1-4                   [8, 32, 90, 90]           --
│    └─Conv2d: 2-16                      [8, 64, 90, 90]           640
│    └─BatchNorm2d: 2-17                 [8, 64, 90, 90]           128
│    └─LeakyReLU: 2-18                   [8, 64, 90, 90]           --
│    └─Conv2d: 2-19                      [8, 32, 90, 90]           2,080
│    └─BatchNorm2d: 2-20                 [8, 32, 90, 90]           64
│    └─LeakyReLU: 2-21                   [8, 32, 90, 90]           --
├─separable_block: 1-5                   [8, 64, 45, 45]           --
│    └─Conv2d: 2-22                      [8, 32, 45, 45]           320
│    └─BatchNorm2d: 2-23                 [8, 32, 45, 45]           64
│    └─LeakyReLU: 2-24                   [8, 32, 45, 45]           --
│    └─Conv2d: 2-25                      [8, 64, 45, 45]           2,112
│    └─BatchNorm2d: 2-26                 [8, 64, 45, 45]           128
│    └─LeakyReLU: 2-27                   [8, 64, 45, 45]           --
├─separable_block: 1-6                   [8, 128, 45, 45]          --
│    └─Conv2d: 2-28                      [8, 64, 45, 45]           640
│    └─BatchNorm2d: 2-29                 [8, 64, 45, 45]           128
│    └─LeakyReLU: 2-30                   [8, 64, 45, 45]           --
│    └─Conv2d: 2-31                      [8, 128, 45, 45]          8,320
│    └─BatchNorm2d: 2-32                 [8, 128, 45, 45]          256
│    └─LeakyReLU: 2-33                   [8, 128, 45, 45]          --
├─separable_block: 1-7                   [8, 32, 23, 23]           --
│    └─Conv2d: 2-34                      [8, 128, 23, 23]          1,280
│    └─BatchNorm2d: 2-35                 [8, 128, 23, 23]          256
│    └─LeakyReLU: 2-36                   [8, 128, 23, 23]          --
│    └─Conv2d: 2-37                      [8, 32, 23, 23]           4,128
│    └─BatchNorm2d: 2-38                 [8, 32, 23, 23]           64
│    └─LeakyReLU: 2-39                   [8, 32, 23, 23]           --
├─separable_block: 1-8                   [8, 128, 23, 23]          --
│    └─Conv2d: 2-40                      [8, 32, 23, 23]           320
│    └─BatchNorm2d: 2-41                 [8, 32, 23, 23]           64
│    └─LeakyReLU: 2-42                   [8, 32, 23, 23]           --
│    └─Conv2d: 2-43                      [8, 128, 23, 23]          4,224
│    └─BatchNorm2d: 2-44                 [8, 128, 23, 23]          256
│    └─LeakyReLU: 2-45                   [8, 128, 23, 23]          --
├─Linear: 1-9                            [8, 8]                    1,032
├─Softmax: 1-10                          [8, 8]                    --
==========================================================================================
Total params: 30,408
Trainable params: 30,408
Non-trainable params: 0
Total mult-adds (M): 859.14
==========================================================================================
Input size (MB): 12.44
Forward/backward pass size (MB): 560.80
Params size (MB): 0.12
Estimated Total Size (MB): 573.37
==========================================================================================
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
best_model                               [8, 8]                    --
├─start: 1-1                             [8, 16, 180, 180]         --
│    └─Conv2d: 2-1                       [8, 16, 180, 180]         448
│    └─BatchNorm2d: 2-2                  [8, 16, 180, 180]         32
│    └─LeakyReLU: 2-3                    [8, 16, 180, 180]         --
├─separable_block: 1-2                   [8, 32, 180, 180]         --
│    └─Conv2d: 2-4                       [8, 16, 180, 180]         160
│    └─BatchNorm2d: 2-5                  [8, 16, 180, 180]         32
│    └─LeakyReLU: 2-6                    [8, 16, 180, 180]         --
│    └─Conv2d: 2-7                       [8, 32, 180, 180]         544
│    └─BatchNorm2d: 2-8                  [8, 32, 180, 180]         64
│    └─LeakyReLU: 2-9                    [8, 32, 180, 180]         --
├─separable_block: 1-3                   [8, 64, 90, 90]           --
│    └─Conv2d: 2-10                      [8, 32, 90, 90]           320
│    └─BatchNorm2d: 2-11                 [8, 32, 90, 90]           64
│    └─LeakyReLU: 2-12                   [8, 32, 90, 90]           --
│    └─Conv2d: 2-13                      [8, 64, 90, 90]           2,112
│    └─BatchNorm2d: 2-14                 [8, 64, 90, 90]           128
│    └─LeakyReLU: 2-15                   [8, 64, 90, 90]           --
├─separable_block: 1-4                   [8, 32, 90, 90]           --
│    └─Conv2d: 2-16                      [8, 64, 90, 90]           640
│    └─BatchNorm2d: 2-17                 [8, 64, 90, 90]           128
│    └─LeakyReLU: 2-18                   [8, 64, 90, 90]           --
│    └─Conv2d: 2-19                      [8, 32, 90, 90]           2,080
│    └─BatchNorm2d: 2-20                 [8, 32, 90, 90]           64
│    └─LeakyReLU: 2-21                   [8, 32, 90, 90]           --
├─separable_block: 1-5                   [8, 64, 45, 45]           --
│    └─Conv2d: 2-22                      [8, 32, 45, 45]           320
│    └─BatchNorm2d: 2-23                 [8, 32, 45, 45]           64
│    └─LeakyReLU: 2-24                   [8, 32, 45, 45]           --
│    └─Conv2d: 2-25                      [8, 64, 45, 45]           2,112
│    └─BatchNorm2d: 2-26                 [8, 64, 45, 45]           128
│    └─LeakyReLU: 2-27                   [8, 64, 45, 45]           --
├─separable_block: 1-6                   [8, 128, 45, 45]          --
│    └─Conv2d: 2-28                      [8, 64, 45, 45]           640
│    └─BatchNorm2d: 2-29                 [8, 64, 45, 45]           128
│    └─LeakyReLU: 2-30                   [8, 64, 45, 45]           --
│    └─Conv2d: 2-31                      [8, 128, 45, 45]          8,320
│    └─BatchNorm2d: 2-32                 [8, 128, 45, 45]          256
│    └─LeakyReLU: 2-33                   [8, 128, 45, 45]          --
├─separable_block: 1-7                   [8, 32, 23, 23]           --
│    └─Conv2d: 2-34                      [8, 128, 23, 23]          1,280
│    └─BatchNorm2d: 2-35                 [8, 128, 23, 23]          256
│    └─LeakyReLU: 2-36                   [8, 128, 23, 23]          --
│    └─Conv2d: 2-37                      [8, 32, 23, 23]           4,128
│    └─BatchNorm2d: 2-38                 [8, 32, 23, 23]           64
│    └─LeakyReLU: 2-39                   [8, 32, 23, 23]           --
├─separable_block: 1-8                   [8, 128, 23, 23]          --
│    └─Conv2d: 2-40                      [8, 32, 23, 23]           320
│    └─BatchNorm2d: 2-41                 [8, 32, 23, 23]           64
│    └─LeakyReLU: 2-42                   [8, 32, 23, 23]           --
│    └─Conv2d: 2-43                      [8, 128, 23, 23]          4,224
│    └─BatchNorm2d: 2-44                 [8, 128, 23, 23]          256
│    └─LeakyReLU: 2-45                   [8, 128, 23, 23]          --
├─Linear: 1-9                            [8, 8]                    1,032
├─Softmax: 1-10                          [8, 8]                    --
==========================================================================================
Total params: 30,408
Trainable params: 30,408
Non-trainable params: 0
Total mult-adds (M): 859.14
==========================================================================================
Input size (MB): 12.44
Forward/backward pass size (MB): 560.80
Params size (MB): 0.12
Estimated Total Size (MB): 573.37
==========================================================================================
Epoch: 0 | Loss: 2.06096, Train Accuracy: 0.20250, Test Loss: 2.05878, Test Accuracy: 0.15297
Epoch: 10 | Loss: 1.70216, Train Accuracy: 0.62500, Test Loss: 1.65448, Test Accuracy: 0.63986
Epoch: 20 | Loss: 1.56474, Train Accuracy: 0.76750, Test Loss: 1.55291, Test Accuracy: 0.74825
Epoch: 30 | Loss: 1.49183, Train Accuracy: 0.82250, Test Loss: 1.48486, Test Accuracy: 0.81862
Epoch: 40 | Loss: 1.46665, Train Accuracy: 0.85250, Test Loss: 1.46936, Test Accuracy: 0.81993
Epoch: 50 | Loss: 1.43478, Train Accuracy: 0.89000, Test Loss: 1.46210, Test Accuracy: 0.83042
Epoch: 60 | Loss: 1.44906, Train Accuracy: 0.87000, Test Loss: 1.48329, Test Accuracy: 0.80332
Epoch: 70 | Loss: 1.40597, Train Accuracy: 0.91000, Test Loss: 1.49379, Test Accuracy: 0.79633
Epoch: 80 | Loss: 1.40643, Train Accuracy: 0.90250, Test Loss: 1.50884, Test Accuracy: 0.77885
Epoch: 90 | Loss: 1.36791, Train Accuracy: 0.94500, Test Loss: 1.48726, Test Accuracy: 0.80157
Epoch: 100 | Loss: 1.37546, Train Accuracy: 0.93750, Test Loss: 1.47288, Test Accuracy: 0.81993
Epoch: 110 | Loss: 1.37276, Train Accuracy: 0.94750, Test Loss: 1.48384, Test Accuracy: 0.81731
Epoch: 120 | Loss: 1.36434, Train Accuracy: 0.93500, Test Loss: 1.46379, Test Accuracy: 0.82780
Epoch: 130 | Loss: 1.35788, Train Accuracy: 0.95750, Test Loss: 1.48916, Test Accuracy: 0.80157
Epoch: 140 | Loss: 1.36002, Train Accuracy: 0.96500, Test Loss: 1.44969, Test Accuracy: 0.84047
Epoch: 150 | Loss: 1.36438, Train Accuracy: 0.93500, Test Loss: 1.47881, Test Accuracy: 0.81075
Epoch: 160 | Loss: 1.35039, Train Accuracy: 0.95750, Test Loss: 1.45941, Test Accuracy: 0.82649
Epoch: 170 | Loss: 1.33854, Train Accuracy: 0.96750, Test Loss: 1.45187, Test Accuracy: 0.84484
Epoch: 180 | Loss: 1.34643, Train Accuracy: 0.95750, Test Loss: 1.46136, Test Accuracy: 0.83566
Epoch: 190 | Loss: 1.33332, Train Accuracy: 0.96250, Test Loss: 1.47231, Test Accuracy: 0.82212