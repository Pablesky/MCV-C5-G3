==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
best_model                               [8, 8]                    --
├─start: 1-1                             [8, 16, 180, 180]         --
│    └─Conv2d: 2-1                       [8, 16, 180, 180]         448
│    └─BatchNorm2d: 2-2                  [8, 16, 180, 180]         32
│    └─LeakyReLU: 2-3                    [8, 16, 180, 180]         --
├─separable_block: 1-2                   [8, 32, 180, 180]         --
│    └─Conv2d: 2-4                       [8, 16, 180, 180]         160
│    └─BatchNorm2d: 2-5                  [8, 16, 180, 180]         32
│    └─LeakyReLU: 2-6                    [8, 16, 180, 180]         --
│    └─Conv2d: 2-7                       [8, 32, 180, 180]         544
│    └─BatchNorm2d: 2-8                  [8, 32, 180, 180]         64
│    └─LeakyReLU: 2-9                    [8, 32, 180, 180]         --
├─separable_block: 1-3                   [8, 64, 90, 90]           --
│    └─Conv2d: 2-10                      [8, 32, 90, 90]           320
│    └─BatchNorm2d: 2-11                 [8, 32, 90, 90]           64
│    └─LeakyReLU: 2-12                   [8, 32, 90, 90]           --
│    └─Conv2d: 2-13                      [8, 64, 90, 90]           2,112
│    └─BatchNorm2d: 2-14                 [8, 64, 90, 90]           128
│    └─LeakyReLU: 2-15                   [8, 64, 90, 90]           --
├─separable_block: 1-4                   [8, 32, 90, 90]           --
│    └─Conv2d: 2-16                      [8, 64, 90, 90]           640
│    └─BatchNorm2d: 2-17                 [8, 64, 90, 90]           128
│    └─LeakyReLU: 2-18                   [8, 64, 90, 90]           --
│    └─Conv2d: 2-19                      [8, 32, 90, 90]           2,080
│    └─BatchNorm2d: 2-20                 [8, 32, 90, 90]           64
│    └─LeakyReLU: 2-21                   [8, 32, 90, 90]           --
├─separable_block: 1-5                   [8, 64, 45, 45]           --
│    └─Conv2d: 2-22                      [8, 32, 45, 45]           320
│    └─BatchNorm2d: 2-23                 [8, 32, 45, 45]           64
│    └─LeakyReLU: 2-24                   [8, 32, 45, 45]           --
│    └─Conv2d: 2-25                      [8, 64, 45, 45]           2,112
│    └─BatchNorm2d: 2-26                 [8, 64, 45, 45]           128
│    └─LeakyReLU: 2-27                   [8, 64, 45, 45]           --
├─separable_block: 1-6                   [8, 128, 45, 45]          --
│    └─Conv2d: 2-28                      [8, 64, 45, 45]           640
│    └─BatchNorm2d: 2-29                 [8, 64, 45, 45]           128
│    └─LeakyReLU: 2-30                   [8, 64, 45, 45]           --
│    └─Conv2d: 2-31                      [8, 128, 45, 45]          8,320
│    └─BatchNorm2d: 2-32                 [8, 128, 45, 45]          256
│    └─LeakyReLU: 2-33                   [8, 128, 45, 45]          --
├─separable_block: 1-7                   [8, 32, 23, 23]           --
│    └─Conv2d: 2-34                      [8, 128, 23, 23]          1,280
│    └─BatchNorm2d: 2-35                 [8, 128, 23, 23]          256
│    └─LeakyReLU: 2-36                   [8, 128, 23, 23]          --
│    └─Conv2d: 2-37                      [8, 32, 23, 23]           4,128
│    └─BatchNorm2d: 2-38                 [8, 32, 23, 23]           64
│    └─LeakyReLU: 2-39                   [8, 32, 23, 23]           --
├─separable_block: 1-8                   [8, 128, 23, 23]          --
│    └─Conv2d: 2-40                      [8, 32, 23, 23]           320
│    └─BatchNorm2d: 2-41                 [8, 32, 23, 23]           64
│    └─LeakyReLU: 2-42                   [8, 32, 23, 23]           --
│    └─Conv2d: 2-43                      [8, 128, 23, 23]          4,224
│    └─BatchNorm2d: 2-44                 [8, 128, 23, 23]          256
│    └─LeakyReLU: 2-45                   [8, 128, 23, 23]          --
├─Linear: 1-9                            [8, 8]                    1,032
├─Softmax: 1-10                          [8, 8]                    --
==========================================================================================
Total params: 30,408
Trainable params: 30,408
Non-trainable params: 0
Total mult-adds (M): 859.14
==========================================================================================
Input size (MB): 12.44
Forward/backward pass size (MB): 560.80
Params size (MB): 0.12
Estimated Total Size (MB): 573.37
==========================================================================================
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
best_model                               [8, 8]                    --
├─start: 1-1                             [8, 16, 180, 180]         --
│    └─Conv2d: 2-1                       [8, 16, 180, 180]         448
│    └─BatchNorm2d: 2-2                  [8, 16, 180, 180]         32
│    └─LeakyReLU: 2-3                    [8, 16, 180, 180]         --
├─separable_block: 1-2                   [8, 32, 180, 180]         --
│    └─Conv2d: 2-4                       [8, 16, 180, 180]         160
│    └─BatchNorm2d: 2-5                  [8, 16, 180, 180]         32
│    └─LeakyReLU: 2-6                    [8, 16, 180, 180]         --
│    └─Conv2d: 2-7                       [8, 32, 180, 180]         544
│    └─BatchNorm2d: 2-8                  [8, 32, 180, 180]         64
│    └─LeakyReLU: 2-9                    [8, 32, 180, 180]         --
├─separable_block: 1-3                   [8, 64, 90, 90]           --
│    └─Conv2d: 2-10                      [8, 32, 90, 90]           320
│    └─BatchNorm2d: 2-11                 [8, 32, 90, 90]           64
│    └─LeakyReLU: 2-12                   [8, 32, 90, 90]           --
│    └─Conv2d: 2-13                      [8, 64, 90, 90]           2,112
│    └─BatchNorm2d: 2-14                 [8, 64, 90, 90]           128
│    └─LeakyReLU: 2-15                   [8, 64, 90, 90]           --
├─separable_block: 1-4                   [8, 32, 90, 90]           --
│    └─Conv2d: 2-16                      [8, 64, 90, 90]           640
│    └─BatchNorm2d: 2-17                 [8, 64, 90, 90]           128
│    └─LeakyReLU: 2-18                   [8, 64, 90, 90]           --
│    └─Conv2d: 2-19                      [8, 32, 90, 90]           2,080
│    └─BatchNorm2d: 2-20                 [8, 32, 90, 90]           64
│    └─LeakyReLU: 2-21                   [8, 32, 90, 90]           --
├─separable_block: 1-5                   [8, 64, 45, 45]           --
│    └─Conv2d: 2-22                      [8, 32, 45, 45]           320
│    └─BatchNorm2d: 2-23                 [8, 32, 45, 45]           64
│    └─LeakyReLU: 2-24                   [8, 32, 45, 45]           --
│    └─Conv2d: 2-25                      [8, 64, 45, 45]           2,112
│    └─BatchNorm2d: 2-26                 [8, 64, 45, 45]           128
│    └─LeakyReLU: 2-27                   [8, 64, 45, 45]           --
├─separable_block: 1-6                   [8, 128, 45, 45]          --
│    └─Conv2d: 2-28                      [8, 64, 45, 45]           640
│    └─BatchNorm2d: 2-29                 [8, 64, 45, 45]           128
│    └─LeakyReLU: 2-30                   [8, 64, 45, 45]           --
│    └─Conv2d: 2-31                      [8, 128, 45, 45]          8,320
│    └─BatchNorm2d: 2-32                 [8, 128, 45, 45]          256
│    └─LeakyReLU: 2-33                   [8, 128, 45, 45]          --
├─separable_block: 1-7                   [8, 32, 23, 23]           --
│    └─Conv2d: 2-34                      [8, 128, 23, 23]          1,280
│    └─BatchNorm2d: 2-35                 [8, 128, 23, 23]          256
│    └─LeakyReLU: 2-36                   [8, 128, 23, 23]          --
│    └─Conv2d: 2-37                      [8, 32, 23, 23]           4,128
│    └─BatchNorm2d: 2-38                 [8, 32, 23, 23]           64
│    └─LeakyReLU: 2-39                   [8, 32, 23, 23]           --
├─separable_block: 1-8                   [8, 128, 23, 23]          --
│    └─Conv2d: 2-40                      [8, 32, 23, 23]           320
│    └─BatchNorm2d: 2-41                 [8, 32, 23, 23]           64
│    └─LeakyReLU: 2-42                   [8, 32, 23, 23]           --
│    └─Conv2d: 2-43                      [8, 128, 23, 23]          4,224
│    └─BatchNorm2d: 2-44                 [8, 128, 23, 23]          256
│    └─LeakyReLU: 2-45                   [8, 128, 23, 23]          --
├─Linear: 1-9                            [8, 8]                    1,032
├─Softmax: 1-10                          [8, 8]                    --
==========================================================================================
Total params: 30,408
Trainable params: 30,408
Non-trainable params: 0
Total mult-adds (M): 859.14
==========================================================================================
Input size (MB): 12.44
Forward/backward pass size (MB): 560.80
Params size (MB): 0.12
Estimated Total Size (MB): 573.37
==========================================================================================
Epoch: 0 | Loss: 2.06983, Train Accuracy: 0.17000, Test Loss: 2.11033, Test Accuracy: 0.09178
Epoch: 10 | Loss: 1.86038, Train Accuracy: 0.41000, Test Loss: 1.86144, Test Accuracy: 0.39336
Epoch: 20 | Loss: 1.84687, Train Accuracy: 0.45750, Test Loss: 1.84483, Test Accuracy: 0.43488
Epoch: 30 | Loss: 1.79062, Train Accuracy: 0.55000, Test Loss: 1.77908, Test Accuracy: 0.51617
Epoch: 40 | Loss: 1.79228, Train Accuracy: 0.52750, Test Loss: 1.78193, Test Accuracy: 0.50918
Epoch: 50 | Loss: 1.78287, Train Accuracy: 0.55250, Test Loss: 1.78609, Test Accuracy: 0.48820
Epoch: 60 | Loss: 1.76862, Train Accuracy: 0.53250, Test Loss: 1.85018, Test Accuracy: 0.45323
Epoch: 70 | Loss: 1.77586, Train Accuracy: 0.55250, Test Loss: 1.75626, Test Accuracy: 0.52885
Epoch: 80 | Loss: 1.77958, Train Accuracy: 0.55250, Test Loss: 1.75460, Test Accuracy: 0.54108
Epoch: 90 | Loss: 1.76818, Train Accuracy: 0.55000, Test Loss: 1.75818, Test Accuracy: 0.52404
Epoch: 100 | Loss: 1.77120, Train Accuracy: 0.55500, Test Loss: 1.75982, Test Accuracy: 0.51355
Epoch: 110 | Loss: 1.76660, Train Accuracy: 0.55500, Test Loss: 1.75428, Test Accuracy: 0.52404
Epoch: 120 | Loss: 1.76857, Train Accuracy: 0.54750, Test Loss: 1.78715, Test Accuracy: 0.50087
Epoch: 130 | Loss: 1.76822, Train Accuracy: 0.55750, Test Loss: 1.74384, Test Accuracy: 0.52360
Epoch: 140 | Loss: 1.76012, Train Accuracy: 0.55500, Test Loss: 1.73412, Test Accuracy: 0.53802
Epoch: 150 | Loss: 1.76055, Train Accuracy: 0.56250, Test Loss: 1.75960, Test Accuracy: 0.50962
Epoch: 160 | Loss: 1.76272, Train Accuracy: 0.55250, Test Loss: 1.78785, Test Accuracy: 0.49038
Epoch: 170 | Loss: 1.77080, Train Accuracy: 0.55750, Test Loss: 1.75628, Test Accuracy: 0.52666
Epoch: 180 | Loss: 1.75686, Train Accuracy: 0.57250, Test Loss: 1.76248, Test Accuracy: 0.51573
Epoch: 190 | Loss: 1.75677, Train Accuracy: 0.56500, Test Loss: 1.75204, Test Accuracy: 0.52841